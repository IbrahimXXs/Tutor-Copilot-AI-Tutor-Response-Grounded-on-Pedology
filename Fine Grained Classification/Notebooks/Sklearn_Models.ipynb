{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Nov, 2024"
      ],
      "metadata": {
        "id": "II5Ip8v_yZDg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1- Logistic Regression"
      ],
      "metadata": {
        "id": "Xe-bu9taycvv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Expert Human only as an input (Best)"
      ],
      "metadata": {
        "id": "M08dxvlo6d4R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGwOt2AOvnUL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/deduplicated_balanced_shuffled_Train_dataset_GPT4o.csv'\n",
        "val_test_path = '/content/Val:Test Peda.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_path)\n",
        "val_test_data = pd.read_csv(val_test_path)\n",
        "\n",
        "print(\"Train Dataset:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nValidation/Test Dataset:\")\n",
        "print(val_test_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnHZY0eLzp2y",
        "outputId": "48564ee5-e04f-4693-fdbd-b979d54526aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0      1138.0  ||| teacher: How do I calculate 3/8 of 40? |||...   \n",
            "1       375.0  ||| student: ohhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh...   \n",
            "2      1351.0        ||| teacher: What’s 14 - 6? ||| student: 8.   \n",
            "3       944.0  ||| student: i need some help ||| teacher: Sur...   \n",
            "4      1458.0  ||| teacher: Can you show me how to calculate ...   \n",
            "\n",
            "                                  Expert_Human_Tutor          Peda_Strategies  \n",
            "0  Divide 40 by 8 to get one-eighth, then multipl...             provide_hint  \n",
            "1  Great - let's try another problem. Can you red...  provide_similar_problem  \n",
            "2               Correct! Now try calculating 15 - 7.  provide_similar_problem  \n",
            "3  Close! You gave the digit in the ones place. W...       provide_correction  \n",
            "4  Sure! For example, the average of 4, 8, and 12...          provide_example  \n",
            "\n",
            "Validation/Test Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0           0  ||| teacher: Add together all the glasses in t...   \n",
            "1           1  ||| student: soory ||| teacher: It's okay, [ST...   \n",
            "2           2  ||| teacher: Excellent! ||| teacher: A = l x w...   \n",
            "3           3  ||| teacher: When we look at the number of sid...   \n",
            "4           4  ||| teacher: Let's get started. ||| teacher: W...   \n",
            "\n",
            "                                  Expert_Human_Tutor        Peda_Strategies  \n",
            "0  That is so close! Can you double-check your work?           ask_question  \n",
            "1  When we subtract 9 from 5, we need to borrow f...           provide_hint  \n",
            "2                      Great job! What is the width?  affirm_correct_answer  \n",
            "3  Good try! Let's try to count the number of sid...       provide_strategy  \n",
            "4  Good try! But your answer is incorrect - since...           ask_question  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data['Expert_Human_Tutor']\n",
        "y_train = train_data['Peda_Strategies']\n",
        "\n",
        "X_val_test = val_test_data['Expert_Human_Tutor']\n",
        "y_val_test = val_test_data['Peda_Strategies']\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "8dbDnyNW2aNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "X_val_vectorized = vectorizer.transform(X_val)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tGZ0PHb2eZ-",
        "outputId": "4ed542b9-53dd-41f7-b24e-589df48dfc82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 1076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_model = LogisticRegression(max_iter=500, random_state=42)\n",
        "logistic_model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "print(\"Model training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiK2SWBM2otX",
        "outputId": "57617959-8702-437b-d22a-a4bed2fd3fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = logistic_model.predict(X_val_vectorized)\n",
        "\n",
        "print(\"Validation Results:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiCzDdq12t2R",
        "outputId": "20162351-56b3-477e-9f31-b591fa8b5840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.75      0.43      0.55         7\n",
            "           ask_question       0.77      0.82      0.79        49\n",
            "        explain_concept       0.46      0.64      0.53        25\n",
            "     provide_correction       0.29      0.25      0.27         8\n",
            "        provide_example       0.20      0.33      0.25         3\n",
            "           provide_hint       0.20      0.10      0.13        10\n",
            "provide_similar_problem       0.20      0.12      0.15         8\n",
            "       provide_strategy       0.50      0.38      0.43        13\n",
            "\n",
            "               accuracy                           0.56       123\n",
            "              macro avg       0.42      0.38      0.39       123\n",
            "           weighted avg       0.55      0.56      0.55       123\n",
            "\n",
            "Validation Accuracy: 0.5610\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = logistic_model.predict(X_test_vectorized)\n",
        "\n",
        "print(\"Test Results:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "\n",
        "macro_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "print(f\"Macro F1-score: {macro_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLC-21pv2yI7",
        "outputId": "5ad01cae-4617-4cd0-a612-babca28d51ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.60      0.75      0.67         8\n",
            "           ask_question       0.55      0.65      0.59        37\n",
            "        explain_concept       0.37      0.38      0.38        26\n",
            "     provide_correction       0.29      0.14      0.19        14\n",
            "        provide_example       0.14      0.25      0.18         4\n",
            "           provide_hint       0.18      0.25      0.21        12\n",
            "provide_similar_problem       0.67      0.20      0.31        10\n",
            "       provide_strategy       0.88      0.58      0.70        12\n",
            "\n",
            "               accuracy                           0.45       123\n",
            "              macro avg       0.46      0.40      0.40       123\n",
            "           weighted avg       0.48      0.45      0.44       123\n",
            "\n",
            "Test Accuracy: 0.4472\n",
            "Macro F1-score: 0.4029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Expert Human and History as an input"
      ],
      "metadata": {
        "id": "iYdYS_H750mI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/deduplicated_balanced_shuffled_Train_dataset_GPT4o.csv'\n",
        "val_test_path = '/content/Val:Test Peda.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_path)\n",
        "val_test_data = pd.read_csv(val_test_path)\n",
        "\n",
        "print(\"Train Dataset:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nValidation/Test Dataset:\")\n",
        "print(val_test_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlF04BsI5IRB",
        "outputId": "a4db9248-b5b0-48c8-b8a6-f3a10ca8acc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0      1138.0  ||| teacher: How do I calculate 3/8 of 40? |||...   \n",
            "1       375.0  ||| student: ohhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh...   \n",
            "2      1351.0        ||| teacher: What’s 14 - 6? ||| student: 8.   \n",
            "3       944.0  ||| student: i need some help ||| teacher: Sur...   \n",
            "4      1458.0  ||| teacher: Can you show me how to calculate ...   \n",
            "\n",
            "                                  Expert_Human_Tutor          Peda_Strategies  \n",
            "0  Divide 40 by 8 to get one-eighth, then multipl...             provide_hint  \n",
            "1  Great - let's try another problem. Can you red...  provide_similar_problem  \n",
            "2               Correct! Now try calculating 15 - 7.  provide_similar_problem  \n",
            "3  Close! You gave the digit in the ones place. W...       provide_correction  \n",
            "4  Sure! For example, the average of 4, 8, and 12...          provide_example  \n",
            "\n",
            "Validation/Test Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0           0  ||| teacher: Add together all the glasses in t...   \n",
            "1           1  ||| student: soory ||| teacher: It's okay, [ST...   \n",
            "2           2  ||| teacher: Excellent! ||| teacher: A = l x w...   \n",
            "3           3  ||| teacher: When we look at the number of sid...   \n",
            "4           4  ||| teacher: Let's get started. ||| teacher: W...   \n",
            "\n",
            "                                  Expert_Human_Tutor        Peda_Strategies  \n",
            "0  That is so close! Can you double-check your work?           ask_question  \n",
            "1  When we subtract 9 from 5, we need to borrow f...           provide_hint  \n",
            "2                      Great job! What is the width?  affirm_correct_answer  \n",
            "3  Good try! Let's try to count the number of sid...       provide_strategy  \n",
            "4  Good try! But your answer is incorrect - since...           ask_question  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['Combined_Input'] = train_data['History'] + \"SEP\" + train_data['Expert_Human_Tutor']\n",
        "val_test_data['Combined_Input'] = val_test_data['History'] + \"SEP\" + val_test_data['Expert_Human_Tutor']\n",
        "\n",
        "X_train = train_data['Combined_Input']\n",
        "y_train = train_data['Peda_Strategies']\n",
        "\n",
        "X_val_test = val_test_data['Combined_Input']\n",
        "y_val_test = val_test_data['Peda_Strategies']\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "yHiDGUjz6nOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "X_val_vectorized = vectorizer.transform(X_val)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjHXH9WM6qgu",
        "outputId": "e07f0f44-0f34-4f1d-b241-b066d1e353df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 1658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_model = LogisticRegression(max_iter=500, random_state=42)\n",
        "\n",
        "logistic_model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "print(\"Model training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLVFZE4Q7FD7",
        "outputId": "d88cb4c8-4bff-476d-dfd4-49031b97bff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = logistic_model.predict(X_val_vectorized)\n",
        "\n",
        "print(\"Validation Results:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emDzYol_7IWc",
        "outputId": "0a03b982-5aad-4820-9a46-2af99b1904fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.00      0.00      0.00         7\n",
            "           ask_question       0.76      0.76      0.76        49\n",
            "        explain_concept       0.40      0.68      0.50        25\n",
            "     provide_correction       0.14      0.12      0.13         8\n",
            "        provide_example       0.00      0.00      0.00         3\n",
            "           provide_hint       0.10      0.10      0.10        10\n",
            "provide_similar_problem       0.20      0.12      0.15         8\n",
            "       provide_strategy       0.50      0.23      0.32        13\n",
            "\n",
            "               accuracy                           0.49       123\n",
            "              macro avg       0.26      0.25      0.24       123\n",
            "           weighted avg       0.46      0.49      0.46       123\n",
            "\n",
            "Validation Accuracy: 0.4878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = logistic_model.predict(X_test_vectorized)\n",
        "\n",
        "print(\"Test Results:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "\n",
        "macro_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "print(f\"Macro F1-score: {macro_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pU1latCY7MMM",
        "outputId": "4c862cc9-940d-46c1-fd62-c45b2a0afa8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.50      0.38      0.43         8\n",
            "           ask_question       0.47      0.65      0.55        37\n",
            "        explain_concept       0.47      0.69      0.56        26\n",
            "     provide_correction       0.00      0.00      0.00        14\n",
            "        provide_example       1.00      0.50      0.67         4\n",
            "           provide_hint       0.09      0.08      0.09        12\n",
            "provide_similar_problem       0.33      0.10      0.15        10\n",
            "       provide_strategy       0.56      0.42      0.48        12\n",
            "\n",
            "               accuracy                           0.44       123\n",
            "              macro avg       0.43      0.35      0.37       123\n",
            "           weighted avg       0.40      0.44      0.40       123\n",
            "\n",
            "Test Accuracy: 0.4390\n",
            "Macro F1-score: 0.3650\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Use single input but with TDF Vectorizer"
      ],
      "metadata": {
        "id": "xTkFq1nBAClw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/deduplicated_balanced_shuffled_Train_dataset_GPT4o.csv'\n",
        "val_test_path = '/content/Val:Test Peda.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_path)\n",
        "val_test_data = pd.read_csv(val_test_path)\n",
        "\n",
        "print(\"Train Dataset:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nValidation/Test Dataset:\")\n",
        "print(val_test_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Instpsj_Ofw",
        "outputId": "0909d91b-b9af-4a4f-fe93-6cfe0bfaf7c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0      1138.0  ||| teacher: How do I calculate 3/8 of 40? |||...   \n",
            "1       375.0  ||| student: ohhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh...   \n",
            "2      1351.0        ||| teacher: What’s 14 - 6? ||| student: 8.   \n",
            "3       944.0  ||| student: i need some help ||| teacher: Sur...   \n",
            "4      1458.0  ||| teacher: Can you show me how to calculate ...   \n",
            "\n",
            "                                  Expert_Human_Tutor          Peda_Strategies  \n",
            "0  Divide 40 by 8 to get one-eighth, then multipl...             provide_hint  \n",
            "1  Great - let's try another problem. Can you red...  provide_similar_problem  \n",
            "2               Correct! Now try calculating 15 - 7.  provide_similar_problem  \n",
            "3  Close! You gave the digit in the ones place. W...       provide_correction  \n",
            "4  Sure! For example, the average of 4, 8, and 12...          provide_example  \n",
            "\n",
            "Validation/Test Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0           0  ||| teacher: Add together all the glasses in t...   \n",
            "1           1  ||| student: soory ||| teacher: It's okay, [ST...   \n",
            "2           2  ||| teacher: Excellent! ||| teacher: A = l x w...   \n",
            "3           3  ||| teacher: When we look at the number of sid...   \n",
            "4           4  ||| teacher: Let's get started. ||| teacher: W...   \n",
            "\n",
            "                                  Expert_Human_Tutor        Peda_Strategies  \n",
            "0  That is so close! Can you double-check your work?           ask_question  \n",
            "1  When we subtract 9 from 5, we need to borrow f...           provide_hint  \n",
            "2                      Great job! What is the width?  affirm_correct_answer  \n",
            "3  Good try! Let's try to count the number of sid...       provide_strategy  \n",
            "4  Good try! But your answer is incorrect - since...           ask_question  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data['Expert_Human_Tutor']\n",
        "y_train = train_data['Peda_Strategies']\n",
        "\n",
        "X_val_test = val_test_data['Expert_Human_Tutor']\n",
        "y_val_test = val_test_data['Peda_Strategies']\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "b8oPKZDnAKJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
        "\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "X_val_vectorized = vectorizer.transform(X_val)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYvVbuv2ALkS",
        "outputId": "9872b912-c15a-4fdb-e94f-d78b976b3830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 6526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_model = LogisticRegression(max_iter=500, random_state=42)\n",
        "\n",
        "logistic_model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "print(\"Model training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aej4GalGAP9t",
        "outputId": "2862848f-fea7-471f-d636-0a17564cb378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = logistic_model.predict(X_val_vectorized)\n",
        "\n",
        "print(\"Validation Results:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUD1I2HcAjET",
        "outputId": "c6eb6d7d-e0b7-4d98-bf46-947aa2d390a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.67      0.29      0.40         7\n",
            "           ask_question       0.66      0.84      0.74        49\n",
            "        explain_concept       0.37      0.60      0.45        25\n",
            "     provide_correction       0.00      0.00      0.00         8\n",
            "        provide_example       0.00      0.00      0.00         3\n",
            "           provide_hint       0.17      0.10      0.12        10\n",
            "provide_similar_problem       0.00      0.00      0.00         8\n",
            "       provide_strategy       0.60      0.23      0.33        13\n",
            "\n",
            "               accuracy                           0.50       123\n",
            "              macro avg       0.31      0.26      0.26       123\n",
            "           weighted avg       0.45      0.50      0.45       123\n",
            "\n",
            "Validation Accuracy: 0.5041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = logistic_model.predict(X_test_vectorized)\n",
        "\n",
        "print(\"Test Results:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "\n",
        "macro_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "print(f\"Macro F1-score: {macro_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lx3fnpepAlPG",
        "outputId": "5e35b41f-b9db-4a48-d871-7c96fc312499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.78      0.88      0.82         8\n",
            "           ask_question       0.51      0.65      0.57        37\n",
            "        explain_concept       0.32      0.58      0.41        26\n",
            "     provide_correction       0.25      0.07      0.11        14\n",
            "        provide_example       0.50      0.25      0.33         4\n",
            "           provide_hint       0.22      0.17      0.19        12\n",
            "provide_similar_problem       1.00      0.20      0.33        10\n",
            "       provide_strategy       1.00      0.25      0.40        12\n",
            "\n",
            "               accuracy                           0.45       123\n",
            "              macro avg       0.57      0.38      0.40       123\n",
            "           weighted avg       0.52      0.45      0.42       123\n",
            "\n",
            "Test Accuracy: 0.4472\n",
            "Macro F1-score: 0.3968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4 Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4_TszJieCGBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n"
      ],
      "metadata": {
        "id": "63t4v-mYCFhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/deduplicated_balanced_shuffled_Train_dataset_GPT4o.csv'\n",
        "val_test_path = '/content/Val:Test Peda.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_path)\n",
        "val_test_data = pd.read_csv(val_test_path)\n",
        "\n",
        "print(\"Train Dataset:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nValidation/Test Dataset:\")\n",
        "print(val_test_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zyeNr47CKls",
        "outputId": "c219f648-7207-4475-fe72-46d3e9f31166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0      1138.0  ||| teacher: How do I calculate 3/8 of 40? |||...   \n",
            "1       375.0  ||| student: ohhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh...   \n",
            "2      1351.0        ||| teacher: What’s 14 - 6? ||| student: 8.   \n",
            "3       944.0  ||| student: i need some help ||| teacher: Sur...   \n",
            "4      1458.0  ||| teacher: Can you show me how to calculate ...   \n",
            "\n",
            "                                  Expert_Human_Tutor          Peda_Strategies  \n",
            "0  Divide 40 by 8 to get one-eighth, then multipl...             provide_hint  \n",
            "1  Great - let's try another problem. Can you red...  provide_similar_problem  \n",
            "2               Correct! Now try calculating 15 - 7.  provide_similar_problem  \n",
            "3  Close! You gave the digit in the ones place. W...       provide_correction  \n",
            "4  Sure! For example, the average of 4, 8, and 12...          provide_example  \n",
            "\n",
            "Validation/Test Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0           0  ||| teacher: Add together all the glasses in t...   \n",
            "1           1  ||| student: soory ||| teacher: It's okay, [ST...   \n",
            "2           2  ||| teacher: Excellent! ||| teacher: A = l x w...   \n",
            "3           3  ||| teacher: When we look at the number of sid...   \n",
            "4           4  ||| teacher: Let's get started. ||| teacher: W...   \n",
            "\n",
            "                                  Expert_Human_Tutor        Peda_Strategies  \n",
            "0  That is so close! Can you double-check your work?           ask_question  \n",
            "1  When we subtract 9 from 5, we need to borrow f...           provide_hint  \n",
            "2                      Great job! What is the width?  affirm_correct_answer  \n",
            "3  Good try! Let's try to count the number of sid...       provide_strategy  \n",
            "4  Good try! But your answer is incorrect - since...           ask_question  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data['Expert_Human_Tutor']\n",
        "y_train = train_data['Peda_Strategies']\n",
        "\n",
        "X_val_test = val_test_data['Expert_Human_Tutor']\n",
        "y_val_test = val_test_data['Peda_Strategies']\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "tTFMxFbACLz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "X_val_vectorized = vectorizer.transform(X_val)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWKTpM8nCNao",
        "outputId": "c10209d1-05c8-4fac-c304-dacb53ed2395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 1076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    LogisticRegression(max_iter=500, random_state=42),\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train_vectorized, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Od3V6c_KCS1h",
        "outputId": "76e6220b-3a94-47ef-ed20-e4bc17ec0073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "Best Parameters: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = best_model.predict(X_val_vectorized)\n",
        "\n",
        "print(\"Validation Results:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvAhTsEaCeN5",
        "outputId": "ffa9df6f-cff5-411d-b802-3f777a893f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.75      0.43      0.55         7\n",
            "           ask_question       0.76      0.80      0.78        49\n",
            "        explain_concept       0.45      0.68      0.54        25\n",
            "     provide_correction       0.33      0.25      0.29         8\n",
            "        provide_example       0.20      0.33      0.25         3\n",
            "           provide_hint       0.25      0.10      0.14        10\n",
            "provide_similar_problem       0.20      0.12      0.15         8\n",
            "       provide_strategy       0.50      0.38      0.43        13\n",
            "\n",
            "               accuracy                           0.56       123\n",
            "              macro avg       0.43      0.39      0.39       123\n",
            "           weighted avg       0.55      0.56      0.54       123\n",
            "\n",
            "Validation Accuracy: 0.5610\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = best_model.predict(X_test_vectorized)\n",
        "\n",
        "print(\"Test Results:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "\n",
        "macro_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "print(f\"Macro F1-score: {macro_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYdOQAw_Dkqf",
        "outputId": "000d6408-20ac-41bb-8371-024b14f2926a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.60      0.75      0.67         8\n",
            "           ask_question       0.55      0.65      0.59        37\n",
            "        explain_concept       0.32      0.35      0.33        26\n",
            "     provide_correction       0.29      0.14      0.19        14\n",
            "        provide_example       0.14      0.25      0.18         4\n",
            "           provide_hint       0.18      0.25      0.21        12\n",
            "provide_similar_problem       0.67      0.20      0.31        10\n",
            "       provide_strategy       0.86      0.50      0.63        12\n",
            "\n",
            "               accuracy                           0.43       123\n",
            "              macro avg       0.45      0.39      0.39       123\n",
            "           weighted avg       0.46      0.43      0.43       123\n",
            "\n",
            "Test Accuracy: 0.4309\n",
            "Macro F1-score: 0.3889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2- Support Vector Machines"
      ],
      "metadata": {
        "id": "_hcrQnJrFKs1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Expert as an input only (Best)"
      ],
      "metadata": {
        "id": "Hd25ElZEG8r8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n"
      ],
      "metadata": {
        "id": "8m67jMkHDorg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/deduplicated_balanced_shuffled_Train_dataset_GPT4o.csv'\n",
        "val_test_path = '/content/Val:Test Peda.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_path)\n",
        "val_test_data = pd.read_csv(val_test_path)\n",
        "\n",
        "print(\"Train Dataset:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nValidation/Test Dataset:\")\n",
        "print(val_test_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCCwrDj2GL1o",
        "outputId": "c144bca8-13d7-4b42-b240-cae3a5c79d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0      1138.0  ||| teacher: How do I calculate 3/8 of 40? |||...   \n",
            "1       375.0  ||| student: ohhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh...   \n",
            "2      1351.0        ||| teacher: What’s 14 - 6? ||| student: 8.   \n",
            "3       944.0  ||| student: i need some help ||| teacher: Sur...   \n",
            "4      1458.0  ||| teacher: Can you show me how to calculate ...   \n",
            "\n",
            "                                  Expert_Human_Tutor          Peda_Strategies  \n",
            "0  Divide 40 by 8 to get one-eighth, then multipl...             provide_hint  \n",
            "1  Great - let's try another problem. Can you red...  provide_similar_problem  \n",
            "2               Correct! Now try calculating 15 - 7.  provide_similar_problem  \n",
            "3  Close! You gave the digit in the ones place. W...       provide_correction  \n",
            "4  Sure! For example, the average of 4, 8, and 12...          provide_example  \n",
            "\n",
            "Validation/Test Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0           0  ||| teacher: Add together all the glasses in t...   \n",
            "1           1  ||| student: soory ||| teacher: It's okay, [ST...   \n",
            "2           2  ||| teacher: Excellent! ||| teacher: A = l x w...   \n",
            "3           3  ||| teacher: When we look at the number of sid...   \n",
            "4           4  ||| teacher: Let's get started. ||| teacher: W...   \n",
            "\n",
            "                                  Expert_Human_Tutor        Peda_Strategies  \n",
            "0  That is so close! Can you double-check your work?           ask_question  \n",
            "1  When we subtract 9 from 5, we need to borrow f...           provide_hint  \n",
            "2                      Great job! What is the width?  affirm_correct_answer  \n",
            "3  Good try! Let's try to count the number of sid...       provide_strategy  \n",
            "4  Good try! But your answer is incorrect - since...           ask_question  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data['Expert_Human_Tutor']\n",
        "y_train = train_data['Peda_Strategies']\n",
        "\n",
        "X_val_test = val_test_data['Expert_Human_Tutor']\n",
        "y_val_test = val_test_data['Peda_Strategies']\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "OxQWqCASGNG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "X_val_vectorized = vectorizer.transform(X_val)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccTswXYYGaiR",
        "outputId": "dbebcc07-c84d-40e8-e41d-ff5137383b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 1076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = SVC(kernel='linear', probability=True, random_state=42)\n",
        "svm_model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "print(\"SVM model training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TWiu-cUGkCG",
        "outputId": "54568915-48a4-49bb-b6bd-b5c881e8db8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = svm_model.predict(X_val_vectorized)\n",
        "\n",
        "print(\"Validation Results:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDbhR0ZSGpyl",
        "outputId": "182dc327-b0bc-4d50-8461-559c27fcfa5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.67      0.57      0.62         7\n",
            "           ask_question       0.80      0.84      0.82        49\n",
            "        explain_concept       0.41      0.56      0.47        25\n",
            "     provide_correction       0.30      0.38      0.33         8\n",
            "        provide_example       0.20      0.33      0.25         3\n",
            "           provide_hint       0.17      0.10      0.12        10\n",
            "provide_similar_problem       0.33      0.12      0.18         8\n",
            "       provide_strategy       0.50      0.31      0.38        13\n",
            "\n",
            "               accuracy                           0.56       123\n",
            "              macro avg       0.42      0.40      0.40       123\n",
            "           weighted avg       0.55      0.56      0.55       123\n",
            "\n",
            "Validation Accuracy: 0.5610\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = svm_model.predict(X_test_vectorized)\n",
        "\n",
        "print(\"Test Results:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "\n",
        "macro_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "print(f\"Macro F1-score: {macro_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bBOdBHLGsrS",
        "outputId": "bb1c9498-7db0-49c4-a16f-425efb9688bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.60      0.75      0.67         8\n",
            "           ask_question       0.59      0.65      0.62        37\n",
            "        explain_concept       0.39      0.42      0.41        26\n",
            "     provide_correction       0.18      0.14      0.16        14\n",
            "        provide_example       0.20      0.25      0.22         4\n",
            "           provide_hint       0.20      0.25      0.22        12\n",
            "provide_similar_problem       0.60      0.30      0.40        10\n",
            "       provide_strategy       0.75      0.50      0.60        12\n",
            "\n",
            "               accuracy                           0.46       123\n",
            "              macro avg       0.44      0.41      0.41       123\n",
            "           weighted avg       0.47      0.46      0.45       123\n",
            "\n",
            "Test Accuracy: 0.4553\n",
            "Macro F1-score: 0.4117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Expert + History"
      ],
      "metadata": {
        "id": "endTahKrIdUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/deduplicated_balanced_shuffled_Train_dataset_GPT4o.csv'\n",
        "val_test_path = '/content/Val:Test Peda.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_path)\n",
        "val_test_data = pd.read_csv(val_test_path)\n",
        "\n",
        "print(\"Train Dataset:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nValidation/Test Dataset:\")\n",
        "print(val_test_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xE-4a7NIIrjF",
        "outputId": "275564b4-067a-4bc0-adfa-820cbc88dd03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0      1138.0  ||| teacher: How do I calculate 3/8 of 40? |||...   \n",
            "1       375.0  ||| student: ohhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh...   \n",
            "2      1351.0        ||| teacher: What’s 14 - 6? ||| student: 8.   \n",
            "3       944.0  ||| student: i need some help ||| teacher: Sur...   \n",
            "4      1458.0  ||| teacher: Can you show me how to calculate ...   \n",
            "\n",
            "                                  Expert_Human_Tutor          Peda_Strategies  \n",
            "0  Divide 40 by 8 to get one-eighth, then multipl...             provide_hint  \n",
            "1  Great - let's try another problem. Can you red...  provide_similar_problem  \n",
            "2               Correct! Now try calculating 15 - 7.  provide_similar_problem  \n",
            "3  Close! You gave the digit in the ones place. W...       provide_correction  \n",
            "4  Sure! For example, the average of 4, 8, and 12...          provide_example  \n",
            "\n",
            "Validation/Test Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0           0  ||| teacher: Add together all the glasses in t...   \n",
            "1           1  ||| student: soory ||| teacher: It's okay, [ST...   \n",
            "2           2  ||| teacher: Excellent! ||| teacher: A = l x w...   \n",
            "3           3  ||| teacher: When we look at the number of sid...   \n",
            "4           4  ||| teacher: Let's get started. ||| teacher: W...   \n",
            "\n",
            "                                  Expert_Human_Tutor        Peda_Strategies  \n",
            "0  That is so close! Can you double-check your work?           ask_question  \n",
            "1  When we subtract 9 from 5, we need to borrow f...           provide_hint  \n",
            "2                      Great job! What is the width?  affirm_correct_answer  \n",
            "3  Good try! Let's try to count the number of sid...       provide_strategy  \n",
            "4  Good try! But your answer is incorrect - since...           ask_question  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['Combined_Input'] = train_data['History'] + \" \" + train_data['Expert_Human_Tutor']\n",
        "val_test_data['Combined_Input'] = val_test_data['History'] + \" \" + val_test_data['Expert_Human_Tutor']\n",
        "\n",
        "X_train = train_data['Combined_Input']\n",
        "y_train = train_data['Peda_Strategies']\n",
        "\n",
        "X_val_test = val_test_data['Combined_Input']\n",
        "y_val_test = val_test_data['Peda_Strategies']\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "dwB4ZUHpIu97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "X_val_vectorized = vectorizer.transform(X_val)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4qIlFs8I0_A",
        "outputId": "4236d774-467b-4aaa-e5b1-fc1a3ac327c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 1517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = SVC(kernel='linear', probability=True, random_state=42)\n",
        "svm_model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "print(\"SVM model training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8FGFKQhI2gO",
        "outputId": "096d1b03-60ef-4299-af10-a49e559f6527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = svm_model.predict(X_val_vectorized)\n",
        "\n",
        "print(\"Validation Results:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enEkpUITI49W",
        "outputId": "2fbb2b98-45a6-4ae9-9bc3-c80fd74a2105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.33      0.14      0.20         7\n",
            "           ask_question       0.62      0.67      0.65        49\n",
            "        explain_concept       0.28      0.48      0.35        25\n",
            "     provide_correction       0.20      0.12      0.15         8\n",
            "        provide_example       0.00      0.00      0.00         3\n",
            "           provide_hint       0.10      0.10      0.10        10\n",
            "provide_similar_problem       0.40      0.25      0.31         8\n",
            "       provide_strategy       0.75      0.23      0.35        13\n",
            "\n",
            "               accuracy                           0.43       123\n",
            "              macro avg       0.34      0.25      0.26       123\n",
            "           weighted avg       0.45      0.43      0.42       123\n",
            "\n",
            "Validation Accuracy: 0.4309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = svm_model.predict(X_test_vectorized)\n",
        "\n",
        "print(\"Test Results:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "\n",
        "macro_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "print(f\"Macro F1-score: {macro_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUfinJyWI9av",
        "outputId": "ea429f38-afe4-4c57-96f1-2abe63ea2289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.80      0.50      0.62         8\n",
            "           ask_question       0.43      0.68      0.53        37\n",
            "        explain_concept       0.32      0.46      0.38        26\n",
            "     provide_correction       0.00      0.00      0.00        14\n",
            "        provide_example       1.00      0.50      0.67         4\n",
            "           provide_hint       0.08      0.08      0.08        12\n",
            "provide_similar_problem       0.00      0.00      0.00        10\n",
            "       provide_strategy       0.50      0.17      0.25        12\n",
            "\n",
            "               accuracy                           0.37       123\n",
            "              macro avg       0.39      0.30      0.31       123\n",
            "           weighted avg       0.34      0.37      0.33       123\n",
            "\n",
            "Test Accuracy: 0.3740\n",
            "Macro F1-score: 0.3149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 TDF Vectorizer"
      ],
      "metadata": {
        "id": "UfMjBKSMHC4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/deduplicated_balanced_shuffled_Train_dataset_GPT4o.csv'\n",
        "val_test_path = '/content/Val:Test Peda.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_path)\n",
        "val_test_data = pd.read_csv(val_test_path)\n",
        "\n",
        "print(\"Train Dataset:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nValidation/Test Dataset:\")\n",
        "print(val_test_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "korVhxTtG2RY",
        "outputId": "b3b56021-618d-4805-ee13-8a2b0069a3c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0      1138.0  ||| teacher: How do I calculate 3/8 of 40? |||...   \n",
            "1       375.0  ||| student: ohhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh...   \n",
            "2      1351.0        ||| teacher: What’s 14 - 6? ||| student: 8.   \n",
            "3       944.0  ||| student: i need some help ||| teacher: Sur...   \n",
            "4      1458.0  ||| teacher: Can you show me how to calculate ...   \n",
            "\n",
            "                                  Expert_Human_Tutor          Peda_Strategies  \n",
            "0  Divide 40 by 8 to get one-eighth, then multipl...             provide_hint  \n",
            "1  Great - let's try another problem. Can you red...  provide_similar_problem  \n",
            "2               Correct! Now try calculating 15 - 7.  provide_similar_problem  \n",
            "3  Close! You gave the digit in the ones place. W...       provide_correction  \n",
            "4  Sure! For example, the average of 4, 8, and 12...          provide_example  \n",
            "\n",
            "Validation/Test Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0           0  ||| teacher: Add together all the glasses in t...   \n",
            "1           1  ||| student: soory ||| teacher: It's okay, [ST...   \n",
            "2           2  ||| teacher: Excellent! ||| teacher: A = l x w...   \n",
            "3           3  ||| teacher: When we look at the number of sid...   \n",
            "4           4  ||| teacher: Let's get started. ||| teacher: W...   \n",
            "\n",
            "                                  Expert_Human_Tutor        Peda_Strategies  \n",
            "0  That is so close! Can you double-check your work?           ask_question  \n",
            "1  When we subtract 9 from 5, we need to borrow f...           provide_hint  \n",
            "2                      Great job! What is the width?  affirm_correct_answer  \n",
            "3  Good try! Let's try to count the number of sid...       provide_strategy  \n",
            "4  Good try! But your answer is incorrect - since...           ask_question  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data['Expert_Human_Tutor']\n",
        "y_train = train_data['Peda_Strategies']\n",
        "\n",
        "X_val_test = val_test_data['Expert_Human_Tutor']\n",
        "y_val_test = val_test_data['Peda_Strategies']\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "hve_cSuTHJ7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "X_val_vectorized = vectorizer.transform(X_val)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jm1_NBwUHONs",
        "outputId": "3536ab97-39d3-475b-834d-fe793f50be59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 1076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = SVC(kernel='linear', probability=True, random_state=42)\n",
        "svm_model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "print(\"SVM model training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdcSYS90HQna",
        "outputId": "f954e4b3-a857-4228-8022-917513deea05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = svm_model.predict(X_val_vectorized)\n",
        "\n",
        "print(\"Validation Results:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY1Kl3qFHTdZ",
        "outputId": "e243024c-1989-4af9-9daf-ed0a181d709f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.67      0.29      0.40         7\n",
            "           ask_question       0.71      0.84      0.77        49\n",
            "        explain_concept       0.41      0.76      0.54        25\n",
            "     provide_correction       0.33      0.12      0.18         8\n",
            "        provide_example       0.33      0.33      0.33         3\n",
            "           provide_hint       0.25      0.10      0.14        10\n",
            "provide_similar_problem       0.00      0.00      0.00         8\n",
            "       provide_strategy       0.75      0.23      0.35        13\n",
            "\n",
            "               accuracy                           0.55       123\n",
            "              macro avg       0.43      0.33      0.34       123\n",
            "           weighted avg       0.53      0.55      0.51       123\n",
            "\n",
            "Validation Accuracy: 0.5528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = svm_model.predict(X_test_vectorized)\n",
        "\n",
        "print(\"Test Results:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "\n",
        "macro_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "print(f\"Macro F1-score: {macro_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3WVoNHYHWYD",
        "outputId": "eada829f-7b87-4ab9-e8de-66e3c3431f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.83      0.62      0.71         8\n",
            "           ask_question       0.47      0.65      0.55        37\n",
            "        explain_concept       0.33      0.54      0.41        26\n",
            "     provide_correction       0.00      0.00      0.00        14\n",
            "        provide_example       0.17      0.25      0.20         4\n",
            "           provide_hint       0.20      0.17      0.18        12\n",
            "provide_similar_problem       0.00      0.00      0.00        10\n",
            "       provide_strategy       1.00      0.33      0.50        12\n",
            "\n",
            "               accuracy                           0.41       123\n",
            "              macro avg       0.38      0.32      0.32       123\n",
            "           weighted avg       0.39      0.41      0.37       123\n",
            "\n",
            "Test Accuracy: 0.4065\n",
            "Macro F1-score: 0.3192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 Use GridSearch"
      ],
      "metadata": {
        "id": "BSYO_8IlJal5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/deduplicated_balanced_shuffled_Train_dataset_GPT4o.csv'\n",
        "val_test_path = '/content/Val:Test Peda.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_path)\n",
        "val_test_data = pd.read_csv(val_test_path)\n",
        "\n",
        "print(\"Train Dataset:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nValidation/Test Dataset:\")\n",
        "print(val_test_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tCfn8F1H_yB",
        "outputId": "660ab267-e392-4baf-d03f-c419554ad64c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0      1138.0  ||| teacher: How do I calculate 3/8 of 40? |||...   \n",
            "1       375.0  ||| student: ohhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh...   \n",
            "2      1351.0        ||| teacher: What’s 14 - 6? ||| student: 8.   \n",
            "3       944.0  ||| student: i need some help ||| teacher: Sur...   \n",
            "4      1458.0  ||| teacher: Can you show me how to calculate ...   \n",
            "\n",
            "                                  Expert_Human_Tutor          Peda_Strategies  \n",
            "0  Divide 40 by 8 to get one-eighth, then multipl...             provide_hint  \n",
            "1  Great - let's try another problem. Can you red...  provide_similar_problem  \n",
            "2               Correct! Now try calculating 15 - 7.  provide_similar_problem  \n",
            "3  Close! You gave the digit in the ones place. W...       provide_correction  \n",
            "4  Sure! For example, the average of 4, 8, and 12...          provide_example  \n",
            "\n",
            "Validation/Test Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0           0  ||| teacher: Add together all the glasses in t...   \n",
            "1           1  ||| student: soory ||| teacher: It's okay, [ST...   \n",
            "2           2  ||| teacher: Excellent! ||| teacher: A = l x w...   \n",
            "3           3  ||| teacher: When we look at the number of sid...   \n",
            "4           4  ||| teacher: Let's get started. ||| teacher: W...   \n",
            "\n",
            "                                  Expert_Human_Tutor        Peda_Strategies  \n",
            "0  That is so close! Can you double-check your work?           ask_question  \n",
            "1  When we subtract 9 from 5, we need to borrow f...           provide_hint  \n",
            "2                      Great job! What is the width?  affirm_correct_answer  \n",
            "3  Good try! Let's try to count the number of sid...       provide_strategy  \n",
            "4  Good try! But your answer is incorrect - since...           ask_question  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data['Expert_Human_Tutor']\n",
        "y_train = train_data['Peda_Strategies']\n",
        "\n",
        "X_val_test = val_test_data['Expert_Human_Tutor']\n",
        "y_val_test = val_test_data['Peda_Strategies']\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "bZISkIzIJekD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "X_val_vectorized = vectorizer.transform(X_val)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFJltXEwJkTZ",
        "outputId": "6f7503df-0d93-433a-e6c9-4cc0f23b3e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 1076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "svm = SVC(probability=True, random_state=42)\n",
        "\n",
        "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
        "grid_search.fit(X_train_vectorized, y_train)\n",
        "\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSjgOjl-Jl-p",
        "outputId": "4544d761-7c56-45f8-fb8c-de708bd0da4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "Best Parameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = best_svm_model.predict(X_val_vectorized)\n",
        "\n",
        "print(\"Validation Results:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3XInaGfJt0I",
        "outputId": "7a39d8cf-4868-4a1f-a9bf-a3ee7ff3befa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.67      0.29      0.40         7\n",
            "           ask_question       0.83      0.80      0.81        49\n",
            "        explain_concept       0.40      0.84      0.55        25\n",
            "     provide_correction       0.25      0.12      0.17         8\n",
            "        provide_example       0.00      0.00      0.00         3\n",
            "           provide_hint       0.00      0.00      0.00        10\n",
            "provide_similar_problem       0.33      0.12      0.18         8\n",
            "       provide_strategy       0.62      0.38      0.48        13\n",
            "\n",
            "               accuracy                           0.56       123\n",
            "              macro avg       0.39      0.32      0.32       123\n",
            "           weighted avg       0.55      0.56      0.53       123\n",
            "\n",
            "Validation Accuracy: 0.5610\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = best_svm_model.predict(X_test_vectorized)\n",
        "\n",
        "print(\"Test Results:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "\n",
        "macro_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "print(f\"Macro F1-score: {macro_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-Oiin8wJ_Pd",
        "outputId": "b6fbdd74-15a6-480e-fd87-b1cf8ded2d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.67      0.75      0.71         8\n",
            "           ask_question       0.65      0.70      0.68        37\n",
            "        explain_concept       0.33      0.73      0.45        26\n",
            "     provide_correction       0.00      0.00      0.00        14\n",
            "        provide_example       0.00      0.00      0.00         4\n",
            "           provide_hint       0.20      0.08      0.12        12\n",
            "provide_similar_problem       1.00      0.10      0.18        10\n",
            "       provide_strategy       0.33      0.17      0.22        12\n",
            "\n",
            "               accuracy                           0.45       123\n",
            "              macro avg       0.40      0.32      0.29       123\n",
            "           weighted avg       0.44      0.45      0.39       123\n",
            "\n",
            "Test Accuracy: 0.4472\n",
            "Macro F1-score: 0.2944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3- Decision Trees"
      ],
      "metadata": {
        "id": "YOywkVUGKdeN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Expert Human as input only (Best)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "thIbXCX4Kj1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n"
      ],
      "metadata": {
        "id": "DczhUy_nKAos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/deduplicated_balanced_shuffled_Train_dataset_GPT4o.csv'\n",
        "val_test_path = '/content/Val:Test Peda.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_path)\n",
        "val_test_data = pd.read_csv(val_test_path)\n",
        "\n",
        "print(\"Train Dataset:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nValidation/Test Dataset:\")\n",
        "print(val_test_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6jaCsjwK_Dg",
        "outputId": "7247bef6-9895-464c-ba2d-07bf2e23e638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0      1138.0  ||| teacher: How do I calculate 3/8 of 40? |||...   \n",
            "1       375.0  ||| student: ohhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh...   \n",
            "2      1351.0        ||| teacher: What’s 14 - 6? ||| student: 8.   \n",
            "3       944.0  ||| student: i need some help ||| teacher: Sur...   \n",
            "4      1458.0  ||| teacher: Can you show me how to calculate ...   \n",
            "\n",
            "                                  Expert_Human_Tutor          Peda_Strategies  \n",
            "0  Divide 40 by 8 to get one-eighth, then multipl...             provide_hint  \n",
            "1  Great - let's try another problem. Can you red...  provide_similar_problem  \n",
            "2               Correct! Now try calculating 15 - 7.  provide_similar_problem  \n",
            "3  Close! You gave the digit in the ones place. W...       provide_correction  \n",
            "4  Sure! For example, the average of 4, 8, and 12...          provide_example  \n",
            "\n",
            "Validation/Test Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0           0  ||| teacher: Add together all the glasses in t...   \n",
            "1           1  ||| student: soory ||| teacher: It's okay, [ST...   \n",
            "2           2  ||| teacher: Excellent! ||| teacher: A = l x w...   \n",
            "3           3  ||| teacher: When we look at the number of sid...   \n",
            "4           4  ||| teacher: Let's get started. ||| teacher: W...   \n",
            "\n",
            "                                  Expert_Human_Tutor        Peda_Strategies  \n",
            "0  That is so close! Can you double-check your work?           ask_question  \n",
            "1  When we subtract 9 from 5, we need to borrow f...           provide_hint  \n",
            "2                      Great job! What is the width?  affirm_correct_answer  \n",
            "3  Good try! Let's try to count the number of sid...       provide_strategy  \n",
            "4  Good try! But your answer is incorrect - since...           ask_question  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data['Expert_Human_Tutor']\n",
        "y_train = train_data['Peda_Strategies']\n",
        "\n",
        "X_val_test = val_test_data['Expert_Human_Tutor']\n",
        "y_val_test = val_test_data['Peda_Strategies']\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "enQ_egtvLASt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "X_val_vectorized = vectorizer.transform(X_val)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKMmkfC8LCwx",
        "outputId": "04175b52-e297-462e-be37-fbaafc25d3cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 1076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree_model = DecisionTreeClassifier(random_state=42)\n",
        "tree_model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "print(\"Decision Tree model training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LnoQsNALF7t",
        "outputId": "27a62867-4da4-4c40-a22f-d5b393537492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = tree_model.predict(X_val_vectorized)\n",
        "\n",
        "print(\"Validation Results:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DdqzE8aLP1T",
        "outputId": "4590a962-919f-453e-acf1-136f3fe72cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.60      0.43      0.50         7\n",
            "           ask_question       0.76      0.59      0.67        49\n",
            "        explain_concept       0.27      0.40      0.32        25\n",
            "     provide_correction       0.12      0.12      0.12         8\n",
            "        provide_example       0.11      0.33      0.17         3\n",
            "           provide_hint       0.30      0.30      0.30        10\n",
            "provide_similar_problem       0.11      0.12      0.12         8\n",
            "       provide_strategy       0.29      0.15      0.20        13\n",
            "\n",
            "               accuracy                           0.41       123\n",
            "              macro avg       0.32      0.31      0.30       123\n",
            "           weighted avg       0.47      0.41      0.42       123\n",
            "\n",
            "Validation Accuracy: 0.4065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = tree_model.predict(X_test_vectorized)\n",
        "\n",
        "print(\"Test Results:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "\n",
        "macro_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "print(f\"Macro F1-score: {macro_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLPRlb5nLRyC",
        "outputId": "733f6bf4-6bc3-40ae-d702-3fb93674ce0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.60      0.75      0.67         8\n",
            "           ask_question       0.67      0.54      0.60        37\n",
            "        explain_concept       0.32      0.54      0.40        26\n",
            "     provide_correction       0.29      0.14      0.19        14\n",
            "        provide_example       0.00      0.00      0.00         4\n",
            "           provide_hint       0.20      0.17      0.18        12\n",
            "provide_similar_problem       0.36      0.40      0.38        10\n",
            "       provide_strategy       0.33      0.17      0.22        12\n",
            "\n",
            "               accuracy                           0.41       123\n",
            "              macro avg       0.35      0.34      0.33       123\n",
            "           weighted avg       0.42      0.41      0.40       123\n",
            "\n",
            "Test Accuracy: 0.4065\n",
            "Macro F1-score: 0.3299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Hyper-paramters control"
      ],
      "metadata": {
        "id": "O8s3sO7GMSJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "train_path = '/content/deduplicated_balanced_shuffled_Train_dataset_GPT4o.csv'\n",
        "val_test_path = '/content/Val:Test Peda.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_path)\n",
        "val_test_data = pd.read_csv(val_test_path)\n",
        "\n",
        "print(\"Train Dataset:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nValidation/Test Dataset:\")\n",
        "print(val_test_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4abhUSZSLV6V",
        "outputId": "81a3c7c6-ea1d-44d3-889e-e83be0b9232d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0      1138.0  ||| teacher: How do I calculate 3/8 of 40? |||...   \n",
            "1       375.0  ||| student: ohhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh...   \n",
            "2      1351.0        ||| teacher: What’s 14 - 6? ||| student: 8.   \n",
            "3       944.0  ||| student: i need some help ||| teacher: Sur...   \n",
            "4      1458.0  ||| teacher: Can you show me how to calculate ...   \n",
            "\n",
            "                                  Expert_Human_Tutor          Peda_Strategies  \n",
            "0  Divide 40 by 8 to get one-eighth, then multipl...             provide_hint  \n",
            "1  Great - let's try another problem. Can you red...  provide_similar_problem  \n",
            "2               Correct! Now try calculating 15 - 7.  provide_similar_problem  \n",
            "3  Close! You gave the digit in the ones place. W...       provide_correction  \n",
            "4  Sure! For example, the average of 4, 8, and 12...          provide_example  \n",
            "\n",
            "Validation/Test Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0           0  ||| teacher: Add together all the glasses in t...   \n",
            "1           1  ||| student: soory ||| teacher: It's okay, [ST...   \n",
            "2           2  ||| teacher: Excellent! ||| teacher: A = l x w...   \n",
            "3           3  ||| teacher: When we look at the number of sid...   \n",
            "4           4  ||| teacher: Let's get started. ||| teacher: W...   \n",
            "\n",
            "                                  Expert_Human_Tutor        Peda_Strategies  \n",
            "0  That is so close! Can you double-check your work?           ask_question  \n",
            "1  When we subtract 9 from 5, we need to borrow f...           provide_hint  \n",
            "2                      Great job! What is the width?  affirm_correct_answer  \n",
            "3  Good try! Let's try to count the number of sid...       provide_strategy  \n",
            "4  Good try! But your answer is incorrect - since...           ask_question  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data['Expert_Human_Tutor']\n",
        "y_train = train_data['Peda_Strategies']\n",
        "\n",
        "X_val_test = val_test_data['Expert_Human_Tutor']\n",
        "y_val_test = val_test_data['Peda_Strategies']\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "T9lAI7SnMaHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "X_val_vectorized = vectorizer.transform(X_val)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQGaFT7zMd4w",
        "outputId": "6fcbe769-38c8-4d71-e6a4-6a354155f8da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 1076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = tree_model.predict(X_test_vectorized)\n",
        "\n",
        "print(\"Test Results:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "\n",
        "macro_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "print(f\"Macro F1-score: {macro_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DPHXMAzMf-7",
        "outputId": "2ab7448f-8172-4e69-cc7b-63191641c74e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.55      0.75      0.63         8\n",
            "           ask_question       0.54      0.68      0.60        37\n",
            "        explain_concept       0.38      0.42      0.40        26\n",
            "     provide_correction       0.25      0.07      0.11        14\n",
            "        provide_example       0.06      0.25      0.10         4\n",
            "           provide_hint       0.22      0.17      0.19        12\n",
            "provide_similar_problem       0.33      0.20      0.25        10\n",
            "       provide_strategy       0.50      0.08      0.14        12\n",
            "\n",
            "               accuracy                           0.40       123\n",
            "              macro avg       0.35      0.33      0.30       123\n",
            "           weighted avg       0.41      0.40      0.38       123\n",
            "\n",
            "Test Accuracy: 0.3984\n",
            "Macro F1-score: 0.3036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = tree_model.predict(X_val_vectorized)\n",
        "\n",
        "print(\"Validation Results:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeWx2Nh7Mjki",
        "outputId": "e99badb1-116c-4d15-b8c5-a699567ca9f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.67      0.57      0.62         7\n",
            "           ask_question       0.69      0.69      0.69        49\n",
            "        explain_concept       0.25      0.32      0.28        25\n",
            "     provide_correction       0.00      0.00      0.00         8\n",
            "        provide_example       0.00      0.00      0.00         3\n",
            "           provide_hint       0.38      0.30      0.33        10\n",
            "provide_similar_problem       0.17      0.12      0.14         8\n",
            "       provide_strategy       0.50      0.08      0.13        13\n",
            "\n",
            "               accuracy                           0.41       123\n",
            "              macro avg       0.33      0.26      0.27       123\n",
            "           weighted avg       0.46      0.41      0.42       123\n",
            "\n",
            "Validation Accuracy: 0.4146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = tree_model.predict(X_test_vectorized)\n",
        "\n",
        "print(\"Test Results:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "\n",
        "macro_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "print(f\"Macro F1-score: {macro_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3RrdXipMmFr",
        "outputId": "5384bc97-007a-4fc2-b80f-b5fad045d8e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.55      0.75      0.63         8\n",
            "           ask_question       0.54      0.68      0.60        37\n",
            "        explain_concept       0.38      0.42      0.40        26\n",
            "     provide_correction       0.25      0.07      0.11        14\n",
            "        provide_example       0.06      0.25      0.10         4\n",
            "           provide_hint       0.22      0.17      0.19        12\n",
            "provide_similar_problem       0.33      0.20      0.25        10\n",
            "       provide_strategy       0.50      0.08      0.14        12\n",
            "\n",
            "               accuracy                           0.40       123\n",
            "              macro avg       0.35      0.33      0.30       123\n",
            "           weighted avg       0.41      0.40      0.38       123\n",
            "\n",
            "Test Accuracy: 0.3984\n",
            "Macro F1-score: 0.3036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4- Random Forest"
      ],
      "metadata": {
        "id": "TS2K5v-xS7Zw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Expert as input only"
      ],
      "metadata": {
        "id": "GTjwhHzrS_lM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n"
      ],
      "metadata": {
        "id": "doGtzkKRS9b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/deduplicated_balanced_shuffled_Train_dataset_GPT4o.csv'\n",
        "val_test_path = '/content/Val:Test Peda.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_path)\n",
        "val_test_data = pd.read_csv(val_test_path)\n",
        "\n",
        "print(\"Train Dataset:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nValidation/Test Dataset:\")\n",
        "print(val_test_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ5GITMGMp9G",
        "outputId": "3ba47d7a-f525-4fa0-acee-d76ce9321955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0      1138.0  ||| teacher: How do I calculate 3/8 of 40? |||...   \n",
            "1       375.0  ||| student: ohhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh...   \n",
            "2      1351.0        ||| teacher: What’s 14 - 6? ||| student: 8.   \n",
            "3       944.0  ||| student: i need some help ||| teacher: Sur...   \n",
            "4      1458.0  ||| teacher: Can you show me how to calculate ...   \n",
            "\n",
            "                                  Expert_Human_Tutor          Peda_Strategies  \n",
            "0  Divide 40 by 8 to get one-eighth, then multipl...             provide_hint  \n",
            "1  Great - let's try another problem. Can you red...  provide_similar_problem  \n",
            "2               Correct! Now try calculating 15 - 7.  provide_similar_problem  \n",
            "3  Close! You gave the digit in the ones place. W...       provide_correction  \n",
            "4  Sure! For example, the average of 4, 8, and 12...          provide_example  \n",
            "\n",
            "Validation/Test Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0           0  ||| teacher: Add together all the glasses in t...   \n",
            "1           1  ||| student: soory ||| teacher: It's okay, [ST...   \n",
            "2           2  ||| teacher: Excellent! ||| teacher: A = l x w...   \n",
            "3           3  ||| teacher: When we look at the number of sid...   \n",
            "4           4  ||| teacher: Let's get started. ||| teacher: W...   \n",
            "\n",
            "                                  Expert_Human_Tutor        Peda_Strategies  \n",
            "0  That is so close! Can you double-check your work?           ask_question  \n",
            "1  When we subtract 9 from 5, we need to borrow f...           provide_hint  \n",
            "2                      Great job! What is the width?  affirm_correct_answer  \n",
            "3  Good try! Let's try to count the number of sid...       provide_strategy  \n",
            "4  Good try! But your answer is incorrect - since...           ask_question  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data['Expert_Human_Tutor']\n",
        "y_train = train_data['Peda_Strategies']\n",
        "\n",
        "X_val_test = val_test_data['Expert_Human_Tutor']\n",
        "y_val_test = val_test_data['Peda_Strategies']\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "1AhZI72ETUyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "X_val_vectorized = vectorizer.transform(X_val)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qcGTCt_TXPx",
        "outputId": "ddbd5e8b-ddf6-4aeb-d804-735775ef5085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 1076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=20, min_samples_split=5, min_samples_leaf=2)\n",
        "\n",
        "\n",
        "rf_model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "print(\"Random Forest model training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZynfgvgTbq9",
        "outputId": "fa707be2-d65f-47b4-c320-4cbeabaf9671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = rf_model.predict(X_val_vectorized)\n",
        "\n",
        "print(\"Validation Results:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Benee5CcTdyw",
        "outputId": "92742bd6-9c83-4337-fd9d-0c4ba60e38ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.60      0.43      0.50         7\n",
            "           ask_question       0.63      0.84      0.72        49\n",
            "        explain_concept       0.30      0.24      0.27        25\n",
            "     provide_correction       0.12      0.12      0.12         8\n",
            "        provide_example       0.00      0.00      0.00         3\n",
            "           provide_hint       0.60      0.30      0.40        10\n",
            "provide_similar_problem       0.20      0.25      0.22         8\n",
            "       provide_strategy       0.50      0.15      0.24        13\n",
            "\n",
            "               accuracy                           0.47       123\n",
            "              macro avg       0.37      0.29      0.31       123\n",
            "           weighted avg       0.47      0.47      0.45       123\n",
            "\n",
            "Validation Accuracy: 0.4715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = rf_model.predict(X_test_vectorized)\n",
        "\n",
        "print(\"Test Results:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "\n",
        "macro_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "print(f\"Macro F1-score: {macro_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT5ts-PWThbj",
        "outputId": "91b306f9-c15a-4503-ff5f-b6b63542091a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.46      0.75      0.57         8\n",
            "           ask_question       0.46      0.78      0.58        37\n",
            "        explain_concept       0.41      0.46      0.44        26\n",
            "     provide_correction       0.00      0.00      0.00        14\n",
            "        provide_example       0.33      0.50      0.40         4\n",
            "           provide_hint       0.33      0.08      0.13        12\n",
            "provide_similar_problem       1.00      0.30      0.46        10\n",
            "       provide_strategy       0.75      0.25      0.38        12\n",
            "\n",
            "               accuracy                           0.46       123\n",
            "              macro avg       0.47      0.39      0.37       123\n",
            "           weighted avg       0.45      0.46      0.40       123\n",
            "\n",
            "Test Accuracy: 0.4553\n",
            "Macro F1-score: 0.3697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5- k-Nearest"
      ],
      "metadata": {
        "id": "zQRzTD0lZDk7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 Input only Expert_Human_Tutor"
      ],
      "metadata": {
        "id": "9WHzJ89_ZHjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n"
      ],
      "metadata": {
        "id": "B439xDRUUYEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/deduplicated_balanced_shuffled_Train_dataset_GPT4o.csv'\n",
        "val_test_path = '/content/Val:Test Peda.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_path)\n",
        "val_test_data = pd.read_csv(val_test_path)\n",
        "\n",
        "print(\"Train Dataset:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nValidation/Test Dataset:\")\n",
        "print(val_test_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pntOfKMlZPqi",
        "outputId": "e774b925-cceb-4513-88c0-6615c2fe5ef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0      1138.0  ||| teacher: How do I calculate 3/8 of 40? |||...   \n",
            "1       375.0  ||| student: ohhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh...   \n",
            "2      1351.0        ||| teacher: What’s 14 - 6? ||| student: 8.   \n",
            "3       944.0  ||| student: i need some help ||| teacher: Sur...   \n",
            "4      1458.0  ||| teacher: Can you show me how to calculate ...   \n",
            "\n",
            "                                  Expert_Human_Tutor          Peda_Strategies  \n",
            "0  Divide 40 by 8 to get one-eighth, then multipl...             provide_hint  \n",
            "1  Great - let's try another problem. Can you red...  provide_similar_problem  \n",
            "2               Correct! Now try calculating 15 - 7.  provide_similar_problem  \n",
            "3  Close! You gave the digit in the ones place. W...       provide_correction  \n",
            "4  Sure! For example, the average of 4, 8, and 12...          provide_example  \n",
            "\n",
            "Validation/Test Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0           0  ||| teacher: Add together all the glasses in t...   \n",
            "1           1  ||| student: soory ||| teacher: It's okay, [ST...   \n",
            "2           2  ||| teacher: Excellent! ||| teacher: A = l x w...   \n",
            "3           3  ||| teacher: When we look at the number of sid...   \n",
            "4           4  ||| teacher: Let's get started. ||| teacher: W...   \n",
            "\n",
            "                                  Expert_Human_Tutor        Peda_Strategies  \n",
            "0  That is so close! Can you double-check your work?           ask_question  \n",
            "1  When we subtract 9 from 5, we need to borrow f...           provide_hint  \n",
            "2                      Great job! What is the width?  affirm_correct_answer  \n",
            "3  Good try! Let's try to count the number of sid...       provide_strategy  \n",
            "4  Good try! But your answer is incorrect - since...           ask_question  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data['Expert_Human_Tutor']\n",
        "y_train = train_data['Peda_Strategies']\n",
        "\n",
        "X_val_test = val_test_data['Expert_Human_Tutor']\n",
        "y_val_test = val_test_data['Peda_Strategies']\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "q_rnLBhsZRYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "X_val_vectorized = vectorizer.transform(X_val)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV8PurmqZTna",
        "outputId": "fc01868a-8d1d-496f-b7c3-d6abda165214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 1076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn_model = KNeighborsClassifier(n_neighbors=1)\n",
        "\n",
        "knn_model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "print(\"k-NN model training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tVB5AwBZXz3",
        "outputId": "1283101b-789a-4dcd-82a0-752754eb72d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k-NN model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = knn_model.predict(X_val_vectorized)\n",
        "\n",
        "print(\"Validation Results:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvdYiyZiZa5f",
        "outputId": "d056a23a-5e97-4dcd-f8be-c80c7f602a91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.33      0.57      0.42         7\n",
            "           ask_question       0.65      0.69      0.67        49\n",
            "        explain_concept       0.42      0.32      0.36        25\n",
            "     provide_correction       0.12      0.12      0.12         8\n",
            "        provide_example       0.17      0.33      0.22         3\n",
            "           provide_hint       0.10      0.10      0.10        10\n",
            "provide_similar_problem       0.12      0.12      0.12         8\n",
            "       provide_strategy       0.50      0.31      0.38        13\n",
            "\n",
            "               accuracy                           0.44       123\n",
            "              macro avg       0.30      0.32      0.30       123\n",
            "           weighted avg       0.45      0.44      0.44       123\n",
            "\n",
            "Validation Accuracy: 0.4390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = knn_model.predict(X_test_vectorized)\n",
        "\n",
        "print(\"Test Results:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "\n",
        "macro_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "print(f\"Macro F1-score: {macro_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HuH4xTYZdaB",
        "outputId": "49886aca-fd28-4fc6-e2c5-bec7ad84e146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.40      1.00      0.57         8\n",
            "           ask_question       0.59      0.65      0.62        37\n",
            "        explain_concept       0.32      0.23      0.27        26\n",
            "     provide_correction       0.33      0.14      0.20        14\n",
            "        provide_example       0.00      0.00      0.00         4\n",
            "           provide_hint       0.14      0.17      0.15        12\n",
            "provide_similar_problem       0.75      0.30      0.43        10\n",
            "       provide_strategy       0.44      0.33      0.38        12\n",
            "\n",
            "               accuracy                           0.40       123\n",
            "              macro avg       0.37      0.35      0.33       123\n",
            "           weighted avg       0.43      0.40      0.39       123\n",
            "\n",
            "Test Accuracy: 0.3984\n",
            "Macro F1-score: 0.3271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 GridSearchCV"
      ],
      "metadata": {
        "id": "l7hzZyT7agxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/deduplicated_balanced_shuffled_Train_dataset_GPT4o.csv'\n",
        "val_test_path = '/content/Val:Test Peda.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_path)\n",
        "val_test_data = pd.read_csv(val_test_path)\n",
        "\n",
        "print(\"Train Dataset:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nValidation/Test Dataset:\")\n",
        "print(val_test_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bbo2kcHwaFmu",
        "outputId": "15854666-51ea-4440-8b1c-cd6f6ba5027e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0      1138.0  ||| teacher: How do I calculate 3/8 of 40? |||...   \n",
            "1       375.0  ||| student: ohhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh...   \n",
            "2      1351.0        ||| teacher: What’s 14 - 6? ||| student: 8.   \n",
            "3       944.0  ||| student: i need some help ||| teacher: Sur...   \n",
            "4      1458.0  ||| teacher: Can you show me how to calculate ...   \n",
            "\n",
            "                                  Expert_Human_Tutor          Peda_Strategies  \n",
            "0  Divide 40 by 8 to get one-eighth, then multipl...             provide_hint  \n",
            "1  Great - let's try another problem. Can you red...  provide_similar_problem  \n",
            "2               Correct! Now try calculating 15 - 7.  provide_similar_problem  \n",
            "3  Close! You gave the digit in the ones place. W...       provide_correction  \n",
            "4  Sure! For example, the average of 4, 8, and 12...          provide_example  \n",
            "\n",
            "Validation/Test Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0           0  ||| teacher: Add together all the glasses in t...   \n",
            "1           1  ||| student: soory ||| teacher: It's okay, [ST...   \n",
            "2           2  ||| teacher: Excellent! ||| teacher: A = l x w...   \n",
            "3           3  ||| teacher: When we look at the number of sid...   \n",
            "4           4  ||| teacher: Let's get started. ||| teacher: W...   \n",
            "\n",
            "                                  Expert_Human_Tutor        Peda_Strategies  \n",
            "0  That is so close! Can you double-check your work?           ask_question  \n",
            "1  When we subtract 9 from 5, we need to borrow f...           provide_hint  \n",
            "2                      Great job! What is the width?  affirm_correct_answer  \n",
            "3  Good try! Let's try to count the number of sid...       provide_strategy  \n",
            "4  Good try! But your answer is incorrect - since...           ask_question  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data['Expert_Human_Tutor']\n",
        "y_train = train_data['Peda_Strategies']\n",
        "\n",
        "X_val_test = val_test_data['Expert_Human_Tutor']\n",
        "y_val_test = val_test_data['Peda_Strategies']\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "qHloXf_5amlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "X_val_vectorized = vectorizer.transform(X_val)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Av8Wd_qaoA0",
        "outputId": "a44e3073-8c86-4528-ea7e-9a56592d90a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 1076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 10],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan', 'cosine']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    KNeighborsClassifier(),\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train_vectorized, y_train)\n",
        "\n",
        "best_knn_model = grid_search.best_estimator_\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "y_val_pred = best_knn_model.predict(X_val_vectorized)\n",
        "print(f\"Validation Accuracy with Tuned k-NN: {accuracy_score(y_val, y_val_pred):.4f}\")\n",
        "\n",
        "y_test_pred = best_knn_model.predict(X_test_vectorized)\n",
        "print(f\"Test Accuracy with Tuned k-NN: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "\n",
        "macro_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "print(f\"Test Macro F1 Score with Tuned k-NN: {macro_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOP0kcyBaq4b",
        "outputId": "f74662c2-c643-4c61-ccd9-0f1b16a9d9da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "Best Parameters: {'metric': 'cosine', 'n_neighbors': 5, 'weights': 'distance'}\n",
            "Validation Accuracy with Tuned k-NN: 0.4715\n",
            "Test Accuracy with Tuned k-NN: 0.4146\n",
            "Test Macro F1 Score with Tuned k-NN: 0.3558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6- Naive Bayes"
      ],
      "metadata": {
        "id": "6teitMGbeBoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Only expert as an input"
      ],
      "metadata": {
        "id": "FuWvPpJNeD3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n"
      ],
      "metadata": {
        "id": "tEZmcOJFemXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/deduplicated_balanced_shuffled_Train_dataset_GPT4o.csv'\n",
        "val_test_path = '/content/Val:Test Peda.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_path)\n",
        "val_test_data = pd.read_csv(val_test_path)\n",
        "\n",
        "print(\"Train Dataset:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nValidation/Test Dataset:\")\n",
        "print(val_test_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V69kvlv7a6HO",
        "outputId": "363a75d5-e0e9-4bf8-e005-3ebbc2bef598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0      1138.0  ||| teacher: How do I calculate 3/8 of 40? |||...   \n",
            "1       375.0  ||| student: ohhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh...   \n",
            "2      1351.0        ||| teacher: What’s 14 - 6? ||| student: 8.   \n",
            "3       944.0  ||| student: i need some help ||| teacher: Sur...   \n",
            "4      1458.0  ||| teacher: Can you show me how to calculate ...   \n",
            "\n",
            "                                  Expert_Human_Tutor          Peda_Strategies  \n",
            "0  Divide 40 by 8 to get one-eighth, then multipl...             provide_hint  \n",
            "1  Great - let's try another problem. Can you red...  provide_similar_problem  \n",
            "2               Correct! Now try calculating 15 - 7.  provide_similar_problem  \n",
            "3  Close! You gave the digit in the ones place. W...       provide_correction  \n",
            "4  Sure! For example, the average of 4, 8, and 12...          provide_example  \n",
            "\n",
            "Validation/Test Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0           0  ||| teacher: Add together all the glasses in t...   \n",
            "1           1  ||| student: soory ||| teacher: It's okay, [ST...   \n",
            "2           2  ||| teacher: Excellent! ||| teacher: A = l x w...   \n",
            "3           3  ||| teacher: When we look at the number of sid...   \n",
            "4           4  ||| teacher: Let's get started. ||| teacher: W...   \n",
            "\n",
            "                                  Expert_Human_Tutor        Peda_Strategies  \n",
            "0  That is so close! Can you double-check your work?           ask_question  \n",
            "1  When we subtract 9 from 5, we need to borrow f...           provide_hint  \n",
            "2                      Great job! What is the width?  affirm_correct_answer  \n",
            "3  Good try! Let's try to count the number of sid...       provide_strategy  \n",
            "4  Good try! But your answer is incorrect - since...           ask_question  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data['Expert_Human_Tutor']\n",
        "y_train = train_data['Peda_Strategies']\n",
        "\n",
        "X_val_test = val_test_data['Expert_Human_Tutor']\n",
        "y_val_test = val_test_data['Peda_Strategies']\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "npEaKQ2deJ08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "X_val_vectorized = vectorizer.transform(X_val)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7yiodUmeL-E",
        "outputId": "70da8a49-ee2c-4cb7-83c9-24fd3e7eb83a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 6526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_model = MultinomialNB()\n",
        "\n",
        "nb_model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "print(\"Naive Bayes model training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m2pQCu3ehZB",
        "outputId": "200bcdda-f522-4fa4-eaab-bc87e701b755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = nb_model.predict(X_val_vectorized)\n",
        "\n",
        "print(\"Validation Results:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iepjy6JCejcc",
        "outputId": "d629033b-6a19-4720-f54b-35f819c0f53d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.67      0.29      0.40         7\n",
            "           ask_question       0.62      0.92      0.74        49\n",
            "        explain_concept       0.38      0.52      0.44        25\n",
            "     provide_correction       0.00      0.00      0.00         8\n",
            "        provide_example       0.00      0.00      0.00         3\n",
            "           provide_hint       0.25      0.20      0.22        10\n",
            "provide_similar_problem       0.00      0.00      0.00         8\n",
            "       provide_strategy       0.67      0.15      0.25        13\n",
            "\n",
            "               accuracy                           0.52       123\n",
            "              macro avg       0.32      0.26      0.26       123\n",
            "           weighted avg       0.45      0.52      0.45       123\n",
            "\n",
            "Validation Accuracy: 0.5203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = nb_model.predict(X_test_vectorized)\n",
        "\n",
        "print(\"Test Results:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "\n",
        "macro_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "print(f\"Macro F1-score: {macro_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdJDwonSeq_P",
        "outputId": "83d4fef6-eac1-4578-8ce6-6d9808096509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.89      1.00      0.94         8\n",
            "           ask_question       0.43      0.70      0.54        37\n",
            "        explain_concept       0.41      0.54      0.47        26\n",
            "     provide_correction       0.50      0.07      0.12        14\n",
            "        provide_example       0.33      0.25      0.29         4\n",
            "           provide_hint       0.27      0.25      0.26        12\n",
            "provide_similar_problem       1.00      0.20      0.33        10\n",
            "       provide_strategy       1.00      0.17      0.29        12\n",
            "\n",
            "               accuracy                           0.46       123\n",
            "              macro avg       0.61      0.40      0.40       123\n",
            "           weighted avg       0.55      0.46      0.43       123\n",
            "\n",
            "Test Accuracy: 0.4634\n",
            "Macro F1-score: 0.4043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7- Perceptron"
      ],
      "metadata": {
        "id": "OncEyA_CihJc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1 Expert as an input only"
      ],
      "metadata": {
        "id": "Lf9cVjf4ijFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n"
      ],
      "metadata": {
        "id": "vmHRmsOQeuke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/deduplicated_balanced_shuffled_Train_dataset_GPT4o.csv'\n",
        "val_test_path = '/content/Val:Test Peda.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_path)\n",
        "val_test_data = pd.read_csv(val_test_path)\n",
        "\n",
        "print(\"Train Dataset:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nValidation/Test Dataset:\")\n",
        "print(val_test_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5MJtffSindw",
        "outputId": "62096ec2-3b83-4fb9-bf16-9e49c2eaf63d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0      1138.0  ||| teacher: How do I calculate 3/8 of 40? |||...   \n",
            "1       375.0  ||| student: ohhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh...   \n",
            "2      1351.0        ||| teacher: What’s 14 - 6? ||| student: 8.   \n",
            "3       944.0  ||| student: i need some help ||| teacher: Sur...   \n",
            "4      1458.0  ||| teacher: Can you show me how to calculate ...   \n",
            "\n",
            "                                  Expert_Human_Tutor          Peda_Strategies  \n",
            "0  Divide 40 by 8 to get one-eighth, then multipl...             provide_hint  \n",
            "1  Great - let's try another problem. Can you red...  provide_similar_problem  \n",
            "2               Correct! Now try calculating 15 - 7.  provide_similar_problem  \n",
            "3  Close! You gave the digit in the ones place. W...       provide_correction  \n",
            "4  Sure! For example, the average of 4, 8, and 12...          provide_example  \n",
            "\n",
            "Validation/Test Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0           0  ||| teacher: Add together all the glasses in t...   \n",
            "1           1  ||| student: soory ||| teacher: It's okay, [ST...   \n",
            "2           2  ||| teacher: Excellent! ||| teacher: A = l x w...   \n",
            "3           3  ||| teacher: When we look at the number of sid...   \n",
            "4           4  ||| teacher: Let's get started. ||| teacher: W...   \n",
            "\n",
            "                                  Expert_Human_Tutor        Peda_Strategies  \n",
            "0  That is so close! Can you double-check your work?           ask_question  \n",
            "1  When we subtract 9 from 5, we need to borrow f...           provide_hint  \n",
            "2                      Great job! What is the width?  affirm_correct_answer  \n",
            "3  Good try! Let's try to count the number of sid...       provide_strategy  \n",
            "4  Good try! But your answer is incorrect - since...           ask_question  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data['Expert_Human_Tutor']\n",
        "y_train = train_data['Peda_Strategies']\n",
        "\n",
        "X_val_test = val_test_data['Expert_Human_Tutor']\n",
        "y_val_test = val_test_data['Peda_Strategies']\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "VigaZqdlipC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
        "\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "X_val_vectorized = vectorizer.transform(X_val)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDkPNg_hj5UG",
        "outputId": "42837756-d542-4a6f-e0b8-94ff9cc787a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 6526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perceptron_model = Perceptron(max_iter=1000, tol=1e-3, random_state=42)\n",
        "\n",
        "perceptron_model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "print(\"Perceptron model training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZCBWUYiitxA",
        "outputId": "19f91b00-1ca5-4fbb-b570-c50a912649c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perceptron model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = perceptron_model.predict(X_val_vectorized)\n",
        "\n",
        "print(\"Validation Results:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-dhFHnyivtP",
        "outputId": "d1ef28d0-155c-48e8-b954-c4fa7b0940e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.29      0.29      0.29         7\n",
            "           ask_question       0.78      0.78      0.78        49\n",
            "        explain_concept       0.41      0.48      0.44        25\n",
            "     provide_correction       0.17      0.12      0.14         8\n",
            "        provide_example       0.00      0.00      0.00         3\n",
            "           provide_hint       0.20      0.20      0.20        10\n",
            "provide_similar_problem       0.20      0.12      0.15         8\n",
            "       provide_strategy       0.23      0.23      0.23        13\n",
            "\n",
            "               accuracy                           0.48       123\n",
            "              macro avg       0.28      0.28      0.28       123\n",
            "           weighted avg       0.47      0.48      0.48       123\n",
            "\n",
            "Validation Accuracy: 0.4797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = perceptron_model.predict(X_test_vectorized)\n",
        "\n",
        "print(\"Test Results:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "\n",
        "macro_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "print(f\"Macro F1-score: {macro_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzGKvOKMix78",
        "outputId": "7aa21c7d-f726-4007-fbc6-2f9bfe3072d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.50      0.62      0.56         8\n",
            "           ask_question       0.62      0.65      0.63        37\n",
            "        explain_concept       0.40      0.38      0.39        26\n",
            "     provide_correction       0.12      0.07      0.09        14\n",
            "        provide_example       0.14      0.25      0.18         4\n",
            "           provide_hint       0.25      0.25      0.25        12\n",
            "provide_similar_problem       0.30      0.30      0.30        10\n",
            "       provide_strategy       0.50      0.50      0.50        12\n",
            "\n",
            "               accuracy                           0.43       123\n",
            "              macro avg       0.35      0.38      0.36       123\n",
            "           weighted avg       0.42      0.43      0.42       123\n",
            "\n",
            "Test Accuracy: 0.4309\n",
            "Macro F1-score: 0.3628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8- Multi-Layer Perceptron"
      ],
      "metadata": {
        "id": "Bph0HTFDjmkZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.1 Input only expert_human_tutor"
      ],
      "metadata": {
        "id": "EzmgjTDdjoaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n"
      ],
      "metadata": {
        "id": "8sxooi1Xi0vK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/deduplicated_balanced_shuffled_Train_dataset_GPT4o.csv'\n",
        "val_test_path = '/content/Val:Test Peda.csv'\n",
        "\n",
        "train_data = pd.read_csv(train_path)\n",
        "val_test_data = pd.read_csv(val_test_path)\n",
        "\n",
        "print(\"Train Dataset:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nValidation/Test Dataset:\")\n",
        "print(val_test_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZXXjA8fjwSl",
        "outputId": "19d21409-944e-4df4-d86a-03720c2abf14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0      1138.0  ||| teacher: How do I calculate 3/8 of 40? |||...   \n",
            "1       375.0  ||| student: ohhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh...   \n",
            "2      1351.0        ||| teacher: What’s 14 - 6? ||| student: 8.   \n",
            "3       944.0  ||| student: i need some help ||| teacher: Sur...   \n",
            "4      1458.0  ||| teacher: Can you show me how to calculate ...   \n",
            "\n",
            "                                  Expert_Human_Tutor          Peda_Strategies  \n",
            "0  Divide 40 by 8 to get one-eighth, then multipl...             provide_hint  \n",
            "1  Great - let's try another problem. Can you red...  provide_similar_problem  \n",
            "2               Correct! Now try calculating 15 - 7.  provide_similar_problem  \n",
            "3  Close! You gave the digit in the ones place. W...       provide_correction  \n",
            "4  Sure! For example, the average of 4, 8, and 12...          provide_example  \n",
            "\n",
            "Validation/Test Dataset:\n",
            "   Unnamed: 0                                            History  \\\n",
            "0           0  ||| teacher: Add together all the glasses in t...   \n",
            "1           1  ||| student: soory ||| teacher: It's okay, [ST...   \n",
            "2           2  ||| teacher: Excellent! ||| teacher: A = l x w...   \n",
            "3           3  ||| teacher: When we look at the number of sid...   \n",
            "4           4  ||| teacher: Let's get started. ||| teacher: W...   \n",
            "\n",
            "                                  Expert_Human_Tutor        Peda_Strategies  \n",
            "0  That is so close! Can you double-check your work?           ask_question  \n",
            "1  When we subtract 9 from 5, we need to borrow f...           provide_hint  \n",
            "2                      Great job! What is the width?  affirm_correct_answer  \n",
            "3  Good try! Let's try to count the number of sid...       provide_strategy  \n",
            "4  Good try! But your answer is incorrect - since...           ask_question  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data['Expert_Human_Tutor']\n",
        "y_train = train_data['Peda_Strategies']\n",
        "\n",
        "X_val_test = val_test_data['Expert_Human_Tutor']\n",
        "y_val_test = val_test_data['Peda_Strategies']\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "3EEOGDAHjyEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
        "\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "\n",
        "X_val_vectorized = vectorizer.transform(X_val)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBX_n0U7j0Zz",
        "outputId": "8ca20b76-b866-4ed3-d0dc-dc91dd02218a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 6526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model = MLPClassifier(\n",
        "    hidden_layer_sizes=(100, 50),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=300,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "mlp_model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "print(\"MLPClassifier training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azvM62P9kMR2",
        "outputId": "08c3501a-3c02-4a1d-c129-3791b105970d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLPClassifier training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = mlp_model.predict(X_val_vectorized)\n",
        "\n",
        "print(\"Validation Results:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E3acKDIkRHG",
        "outputId": "fdab221e-517e-4145-820d-6e5c86a5ff82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       1.00      0.29      0.44         7\n",
            "           ask_question       0.68      0.82      0.74        49\n",
            "        explain_concept       0.39      0.52      0.45        25\n",
            "     provide_correction       0.17      0.12      0.14         8\n",
            "        provide_example       0.12      0.33      0.18         3\n",
            "           provide_hint       0.20      0.10      0.13        10\n",
            "provide_similar_problem       0.33      0.12      0.18         8\n",
            "       provide_strategy       0.57      0.31      0.40        13\n",
            "\n",
            "               accuracy                           0.51       123\n",
            "              macro avg       0.43      0.33      0.33       123\n",
            "           weighted avg       0.52      0.51      0.49       123\n",
            "\n",
            "Validation Accuracy: 0.5122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = mlp_model.predict(X_test_vectorized)\n",
        "\n",
        "print(\"Test Results:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "print(f\"Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "\n",
        "macro_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "print(f\"Macro F1-score: {macro_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojvC0DF8kTyJ",
        "outputId": "6bea9b13-02d9-4070-e778-6a1639dd4a00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "  affirm_correct_answer       0.73      1.00      0.84         8\n",
            "           ask_question       0.61      0.76      0.67        37\n",
            "        explain_concept       0.41      0.42      0.42        26\n",
            "     provide_correction       0.12      0.07      0.09        14\n",
            "        provide_example       0.33      0.25      0.29         4\n",
            "           provide_hint       0.36      0.33      0.35        12\n",
            "provide_similar_problem       0.57      0.40      0.47        10\n",
            "       provide_strategy       0.50      0.42      0.45        12\n",
            "\n",
            "               accuracy                           0.50       123\n",
            "              macro avg       0.45      0.46      0.45       123\n",
            "           weighted avg       0.47      0.50      0.48       123\n",
            "\n",
            "Test Accuracy: 0.5041\n",
            "Macro F1-score: 0.4477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K5yEkIVvkUr3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}